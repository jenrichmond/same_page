---
title: "read_data"
author: "Jen Richmond"
date: "16/02/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

The point of this Rmd is to try and reproduce the cleaning process outlined in the first script /scripts/kidwell_et_al.(2016)/Actual Availability, All Journals.R

# load packages
```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(here)
library(janitor)
library(lubridate)
```

# read data

The script above reads data straight from OSF (clever) but I wrote it to the data_files folder to make it easy to read back in. 

```{r}
kidwell <- read_csv(here::here("data_files", "master_dataset_edited_for_dates.csv")) %>%
  clean_names()

```

# remove articles that are not empirical

```{r}
empirical <- kidwell %>%
  filter(number_of_experiments > 0)
```

# assign journal name

Found this case_when + str_detect  combo came from https://bookdown.org/ansellbr/WEHI_tidyR_course_book/manipulating-data-with-dplyr.html#

I worked out here that order is important. If you put PS as the first case_when, it only ends up capturing 3 journals because it counts CPS and JPSP as PS. Important to put PS as the last case it evaluates. 


```{r}
empirical<- empirical %>%
  mutate(journal = case_when( 
          str_detect(article_id_number,'CPS') ~ "Clinical Psychological Science", 
          str_detect(article_id_number,'DP') ~ "Developmental Psychology", 
          str_detect(article_id_number,'JEPLMC') ~ "Journal of Experimental Psychology: Learning, Memory, and Cognition", 
          str_detect(article_id_number,'JPSP') ~ "Journal of Personality and Social Psychology", 
          str_detect(article_id_number,'PS') ~ "Psychological Science",  TRUE ~ "other")) %>%
           mutate(year = case_when(str_detect(article_id_number,'2012') ~ "2012", 
                             str_detect(article_id_number,'2013') ~ "2013", 
                             str_detect(article_id_number,'2014') ~ "2014", 
                             str_detect(article_id_number,'2015') ~ "2015", 
                             TRUE ~ "other")) %>%
  relocate(journal, .after = article_id_number) %>%
  relocate(year, .before = article_id_number) %>%
  separate(article_id_number, into = c("date", "journal_code"), sep = "\\s", remove = FALSE)

unique(empirical$journal)
unique(empirical$year)

```

```{r}
# change class to date 
empirical$date <- dmy(empirical$date)

#check class
class(empirical$date)

```

# ALL PAPERS BY HALF/YEAR

Add month and halfyear to make plotting by 6 month periods easier. 

```{r}
empirical <- empirical %>%
  mutate(month = month(date)) %>%
  mutate(halfyear = case_when(month <=6 ~ "first", 
                              month > 6 ~ "second")) %>%   
  relocate(month, .before = year) %>%
   relocate(halfyear, .before = year) %>%
    unite("firstsecond", halfyear:year, sep = "_") 

glimpse(empirical)

empirical$firstsecond <- 
  fct_relevel(empirical$firstsecond, c("first_2012", "second_2012", 
                             "first_2013", "second_2013",
                             "first_2014", "second_2014",
                             "first_2015"))

levels(empirical$firstsecond)

```

Create new dfs that filter only papers with open data, papers with badges, and papers where the data is locatable. 
```{r}

open <- empirical %>%
   filter(data_url_links_to %in% c("Independent archive / repository", "Personal site", "Third party site")) 

badge <- open %>%
  rename(badge = did_the_article_receive_a_badge_for_open_data) %>%
  filter(badge == "Yes")

located <- open %>% 
         rename(located = are_the_data_located_at_the_working_page) %>%
  filter(located == "Yes")

```

## count papers per half/year by journal

counting for each year/half, how many papers published in each journal (without using tabyl)

```{r}
count_papers <- empirical %>%
  group_by(firstsecond, journal_code) %>%
  count() %>%
  rename(total_n = n)

count_open <- open %>%
  group_by(firstsecond, journal_code) %>%
  count() %>%
   rename(open_n = n)

count_badge <- badge %>%
  group_by(firstsecond, journal_code) %>%
  count()  %>%
   rename(badge_n = n)

count_located <- located %>%
  group_by(firstsecond, journal_code) %>%
  count() %>%
   rename(located_n = n)
```

## plot articles per half/year by joural code
```{r}

 count_papers %>%
  ggplot(aes(x = firstsecond, y = total_n, colour = journal_code, group = journal_code)) +
  geom_point() +
  geom_line() 


 count_open %>%
  ggplot(aes(x = firstsecond, y = open_n, colour = journal_code, group = journal_code)) +
  geom_point() +
  geom_line() 
 
 
 count_badge %>%
  ggplot(aes(x = firstsecond, y = badge_n, colour = journal_code, group = journal_code)) +
  geom_point() +
  geom_line() 
 
 
 count_located %>%
  ggplot(aes(x = firstsecond, y = located_n, colour = journal_code, group = journal_code)) +
  geom_point() +
  geom_line() 
```

Join paper count and open count with full_join (this leaves the NA if there isn't a value for that combo of half/year + journal = which there is in the open_n variable). Calculate % open. 

```{r}
total <- count_papers %>%
  full_join(count_open) %>%
  full_join(count_badge) %>%
  full_join(count_located) %>%
  mutate_all(~replace(., is.na(.), 0)) %>%
  mutate(percent_open = (open_n/total_n)*100) 
```

Figure 4 plots percent papers where data is ...
- reportedly available
- acutally available
- correct
- usable
- complete

... in 4 categories
- Journals wo badges
- PSCI before badges
- PSCI after badges (not earned)
- PSCI after badges (earned)

```{r}

beforebadges <- c("first_2012", "second_2012", "first_2013", "second_2013")
afterbadges <- c("first_2014", "second_2014", "first_2015")
nobadgejournals <- c("DP", "JEPLMC", "JPSP", "CPS")

total_badges <- total %>%
  mutate(journal_badges = case_when(journal_code %in% nobadgejournals ~ "journals wo badges", 
                        journal_code == "PS" & firstsecond %in% beforebadges ~ "PS before badges", 
                        journal_code == "PS" & firstsecond %in% afterbadges ~ "PS after badges"))
         
        
```


## plot proportion

```{r}
total %>%
  ggplot(aes(x = firstsecond, y = percent_open, group = journal_code, colour = journal_code)) +
  geom_point() +
  geom_line() +
  labs(title = "proportion of papers with open data", y = "Proportion", x = "Time")
```



```{r}
justps <- total %>%
  filter(journal_code == "PS")
```

