# Load packages
library(tidyverse)
library(janitor)
library(here)
library(Hmisc)
library(vcd)
library(irr)
library(psych)

# Cicchetti (1994) gives the following guidelines for interpretation for kappa or ICC inter-rater agreement measures:

#Less than 0.40—poor.
#Between 0.40 and 0.59—fair.
#Between 0.60 and 0.74—good.
#Between 0.75 and 1.00—excellent.

# GOLD STANDARD -----

# Read in Christina's Reliability Checking data - gold standard

gold_standard_data <- read_csv(here("data_files", "data1B_reliability_checking")) %>%
  select(coder_name, article_id_number, data_badge:URL_supplemental_info)

# SCORING THE GOLD STANDARD ----

## Open Data Scores 

# The same scoring system that was used to assign 1A and 1B articles an Open Data score will be used 

# First let's make the relevant data long
gold_data_scoring <- gold_standard_data %>%
  select(coder_name, article_id_number, software, data_statement_present, data_statement_indicates, data_accessible, dataset_URL_working, data_locatable, data_downloadable, data_correspond, data_complete, data_codebook, data_scripts) %>%
  pivot_longer(names_to = "question", values_to = "response", software:data_scripts)

# Now let's assign scores for openness of data
gold_data_scoring <- gold_data_scoring %>%
  mutate(data_score = case_when(question == "software" & response == "No" ~ 0, 
                                question == "software" & response == "Yes" ~ 1, 
                                question == "data_statement_present" & response == "No" ~ 0, 
                                question == "data_statement_present" & response == "Yes" ~ 1,
                                question == "data_statement_indicates" & response == "Unavailable" ~ 0, 
                                question == "data_statement_indicates" & response == "Available" ~ 1,
                                
                                question == "data_accessible" & response == "Not clear" ~ 0, 
                                question == "data_accessible" & response %in% c("Public dataset generated by the authors", "Public dataset generated by others", "Other (please specify):") ~ 2, 
                                question == "dataset_URL_working" & response == "No" ~ 0, 
                                question == "dataset_URL_working" & response == "Yes" ~ 2,
                                question == "data_locatable" & response == "No" ~ 0,
                                question == "data_locatable" & response == "Requires permission" ~ 1, 
                                question == "data_locatable" & response == "Yes" ~ 2,
                                question == "data_downloadable" & response == "No" ~ 0,
                                question == "data_downloadable" & response == "Requires permission" ~ 1, 
                                question == "data_downloadable" & response == "Yes" ~ 2,
                                question == "data_correspond" & response %in% c("Unclear", "No") ~ 0, 
                                question == "data_correspond" & response == "Yes" ~ 2,
                                question == "data_complete" & response %in% c("Unclear whether or not all the data are available", "No, not all of the data are available") ~ 0, 
                                question == "data_complete" & response == "Yes, but only some of the data are available" ~ 1, 
                                question == "data_complete" & response == "Yes, all of the data appear to be available" ~ 2,
                                
                                question == "data_codebook" & response == "No" ~ 0, 
                                question == "data_codebook" & response == "Yes" ~ 5,
                                question == "data_scripts" & response == "No" ~ 0, 
                                question == "data_scripts" & response == "Yes" ~ 5)) %>%
  mutate(data_score = coalesce(data_score, 0))

# Let's create a single open data score for each article 

gold_data_score_summary <- gold_data_scoring %>%
  group_by(article_id_number, coder_name) %>% 
  summarise(total_data_score = sum(data_score))

gold_data_score_summary %>%
  tabyl(total_data_score)

## Open Materials Scores

# Let's make the relevant data long
gold_materials_scoring <- gold_standard_data %>%
  select(coder_name, article_id_number, materials_statement_present, materials_statement_indicates, materials_accessible, materials_URL_working, materials_locatable, materials_downloadable, materials_correspond, materials_complete, materials_explanation) %>%
  pivot_longer(names_to = "question", values_to = "response", materials_statement_present:materials_explanation)

# And let's score the data
gold_materials_scoring <- gold_materials_scoring %>%
  mutate(materials_score = case_when(question == "materials_statement_present" & response =="No" ~ 0,
                                     question == "materials_statement_present"  &  response == "Yes" ~ 1, 
                                     question == "materials_statement_indicates" & response =="Unavailable" ~ 0,
                                     question == "materials_statement_indicates"  &  response == "Available" ~ 1, 
                                     
                                     question == "materials_accessible" & response =="Not clean" ~ 0,
                                     question == "materials_accessible"  &response %in% c("Public set of materials generated by authors", "Public set of materials generated by others", "Other (please specify):") ~ 2, 
                                     question == "materials_URL_working" & response =="No" ~ 0,
                                     question == "materials_URL_working"  &  response == "Yes" ~ 2, 
                                     question == "materials_locatable"  & response== "No" ~ 0,
                                     question == "materials_locatable" & response == "Requires permission" ~ 1,
                                     question == "materials_locatable" & response == "Yes" ~ 2,
                                     question == "materials_downloadable"  & response== "No" ~ 0,
                                     question == "materials_downloadable" & response == "Requires permission" ~ 1,
                                     question == "materials_downloadable" & response == "Yes" ~ 2,
                                     question == "materials_correspond" & response %in% c("Unclear", "No") ~ 0,
                                     question == "materials_correspond" & response == "Yes" ~ 2,
                                     question == "materials_complete" & response %in% c("Unclear whether or not all the materials are available", "No, not all of the materials are available") ~ 0,
                                     question == "materials_complete" & response == "Yes, but only some of the materials are available" ~ 1,
                                     question == "materials_complete" & response == "Yes, all of the materials appear to be available" ~ 2,
                                     
                                     question == "materials_explanation" & response == "No" ~ 0,
                                     question == "materials_explanation" & response == "Yes" ~ 5))  %>%
  mutate(materials_score = coalesce(materials_score, 0))

# Let's create a single open materials score for each article 

gold_materials_score_summary <- gold_materials_scoring %>%
  group_by(article_id_number, coder_name) %>% 
  summarise(total_materials_score = sum(materials_score))

gold_materials_score_summary %>%
  tabyl(total_materials_score)

# Finally, let's create a total Openness Score that sums the total data and total materials scores together
gold_total_summary <- merge(gold_data_score_summary, gold_materials_score_summary, by = "article_id_number")

gold_total_summary <- gold_total_summary %>%
  select(-coder_name.y) %>%
  select(article_id_number:total_materials_score, coder_name = coder_name.x) %>%
  mutate(total_openness_score = total_data_score + total_materials_score) 

gold_reliability_summary <- gold_total_summary %>%
  select(article_id_number, total_openness_score)

# CODERS DATA -----

# let's load in coder's reliability checking data

coders_data <- read_csv(here("data_files", "scored_master_dataset_1B.csv")) %>%
  select(coder_name, article_id_number, total_data_score:total_materials_score) %>%
  filter(article_id_number %in% c("2020-31-3-268", "2020-31-3-293", "2019-30-10-1460", "2020-31-6-729", "2020-31-8-1001", "2019-30-8-1123", "2020-31-7-848", "2020-31-7-873", "2020-31-7-881", "2020-31-8-944", "2019-30-7-1030", "2020-31-3-280", "2020-31-5-505", "2020-31-6-607", "2020-31-10-1283", "2019-30-10-1483", "2019-30-10-1522", "2020-31-5-592", "2020-31-9-1191"))

# let's create a total Openness Score that sums the total data and total materials scores together

coder_total_summary <- coders_data %>%
  mutate(total_openness_score = total_data_score + total_materials_score) 

coder_reliability_summary <- coder_total_summary %>%
  select(coder_name, article_id_number, total_openness_score)

# OVERALL RELIABILITY ----

# let's make the coders' data long
overall <- coder_reliability_summary %>%
  pivot_wider(names_from = coder_name, values_from = total_openness_score) 

# merge gold standard with coders' data
gold_overall_reliability <- merge(overall, gold_reliability_summary, by = "article_id_number")

# let's take out the id column so R doesn't think "ID" is a rater
gold_overall_reliability <- gold_overall_reliability %>%
  select(-article_id_number, `Georgia Saddler`:`patrick mccraw`, gold_standard = total_openness_score)

# let's merge the coders data into one column
gold_overall_reliability <- gold_overall_reliability %>%
  unite("coders_data", `Georgia Saddler`:`patrick mccraw`, remove = TRUE, na.rm = TRUE) %>%
  select(gold_standard, coders_data)

# let's make the coders_data column numeric 
gold_overall_reliability$coders_data <- as.numeric(gold_overall_reliability$coders_data)

# let's run the icc reliability analysis 
icc(gold_overall_reliability, model="oneway", type="agreement", r0 = 0, conf.level = 0.95)

# agreement of coders
agree(gold_overall_reliability, tolerance=5)

# PATRICK'S RELIABILITY ----

# let's filter for Jenn's data alone and make it long
patrick <- coder_reliability_summary %>%
  filter(coder_name == "patrick mccraw") %>%
  pivot_wider(names_from = coder_name, values_from = total_openness_score) 

# filter Christina's data so it only has article's Patrick coded
christina_patrick <- gold_reliability_summary %>%
  filter(article_id_number %in% c("2020-31-3-268", "2020-31-3-293", "2019-30-10-1460", "2020-31-6-729", "2020-31-8-1001")) %>%
  select(article_id_number, gold_standard = total_openness_score)

christina_patrick_reliability <- merge(christina_patrick, patrick, by = "article_id_number")

# let's take out the id column so R doesn't think "ID" is a rater
christina_patrick_reliability <- christina_patrick_reliability %>%
  select(-article_id_number)

# icc reliability analysis
icc(christina_patrick_reliability, model="twoway", type="agreement")

# GOOD reliability

# HELEN'S RELIABILITY ----

# let's filter for Helen's data alone and make it long
helen <- coder_reliability_summary %>%
  filter(coder_name == "Helen Gu") %>%
  pivot_wider(names_from = coder_name, values_from = total_openness_score) 

# filter Christina's data so it only has article's Helen coded
christina_helen <- gold_reliability_summary %>%
  filter(article_id_number %in% c("2019-30-8-1123", "2020-31-7-848", "2020-31-7-873", "2020-31-7-881", "2020-31-8-944")) %>%
  select(article_id_number, gold_standard = total_openness_score)

christina_helen_reliability <- merge(christina_helen, helen, by = "article_id_number")

# let's take out the id column so R doesn't think "ID" is a rater
christina_helen_reliability <- christina_helen_reliability %>%
  select(-article_id_number)

# icc reliability analysis 
icc(christina_helen_reliability, model="twoway", type="agreement")

# EXCELLENT reliability

# GEORGIA'S RELIABILITY ----

# let's filter for Helen's data alone and make it long
georgia <- coder_reliability_summary %>%
  filter(coder_name == "Georgia Saddler") %>%
  pivot_wider(names_from = coder_name, values_from = total_openness_score) 

# filter Christina's data so it only has article's Georgia coded
christina_georgia <- gold_reliability_summary %>%
  filter(article_id_number %in% c("2019-30-7-1030", "2020-31-3-280", "2020-31-5-505", "2020-31-6-607", "2020-31-10-1283")) %>%
  select(article_id_number, gold_standard = total_openness_score)

christina_georgia_reliability <- merge(christina_georgia, georgia, by = "article_id_number")

# let's take out the id column so R doesn't think "ID" is a rater
christina_georgia_reliability <- christina_georgia_reliability %>%
  select(-article_id_number)

# icc reliability analysis 
icc(christina_georgia_reliability, model="twoway", type="agreement")

# EXCELLENT reliability

# WILL'S RELIABILITY ----

# let's filter for Helen's data alone and make it long
will <- coder_reliability_summary %>%
  filter(coder_name == "Will Osmand") %>%
  pivot_wider(names_from = coder_name, values_from = total_openness_score) 

# filter Christina's data so it only has article's Will coded
christina_will <- gold_reliability_summary %>%
  filter(article_id_number %in% c("2019-30-10-1483", "2019-30-10-1522", "2020-31-5-592", "2020-31-9-1191")) %>%
  select(article_id_number, gold_standard = total_openness_score)

christina_will_reliability <- merge(christina_will, will, by = "article_id_number")

# let's take out the id column so R doesn't think "ID" is a rater
christina_will_reliability <- christina_will_reliability %>%
  select(-article_id_number)

# icc reliability analysis 
icc(christina_will_reliability, model="twoway", type="agreement")

# EXCELLENT reliability

# Overall, 1B inter-rater reliability ranges from good to excellent

