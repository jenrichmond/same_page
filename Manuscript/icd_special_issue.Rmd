---
title             : "Are we all on the same page? Subfield differences in open science practice"
shorttitle        : "Subfield "

author: 
  - name          : "Christina Riochios"
    affiliation   : "1"
     # Define only one corresponding author
    address       : "Postal address"
    email         : "c.riochios@unsw.edu.au"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - Conceptualization
      - Methodology
      - Investigation
      - Data curation
      - Visualisation
      - Formal Analysis
      - Writing - Original Draft Preparation
      - Writing - Review & Editing
  - name          : "Jenny L. Richmond"
    affiliation   : "1"
    corresponding : yes 
    email         : "j.richmond@unsw.edu.au"
    role:
      - Conceptualization
      - Methodology
      - Formal Analysis
      - Writing - Original Draft Preparation
      - Writing - Review & Editing
      - Supervision

affiliation:
  - id            : "1"
    institution   : "University of New South Wales"
 
authornote: |
  School of Psychology, UNSW  

abstract: |
  Christina- can you insert abstract here please :)
  
  One or two sentences providing a **basic introduction** to the field,  comprehensible to a scientist in any discipline.
  
  Two to three sentences of **more detailed background**, comprehensible  to scientists in related disciplines.
  
  One sentence clearly stating the **general problem** being addressed by  this particular study.
  
  One sentence summarizing the main result (with the words "**here we show**" or their equivalent).
  
  Two or three sentences explaining what the **main result** reveals in direct comparison to what was thought to be the case previously, or how the  main result adds to previous knowledge.
  
  One or two sentences to put the results into a more **general context**.
  
  Two or three sentences to provide a **broader perspective**, readily comprehensible to a scientist in any discipline.
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["r-references.bib"]

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
library(papaja)
library(tidyverse)
library(janitor)
library(here)
library(ggeasy)
library(apa)
library(papaja)
library(patchwork)
library(afex)
library(report)
library(ggeasy)
library(gghalves)
library(ggsignif)

source("R_rainclouds copy.R")
r_refs("r-references.bib")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(1)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

# INTRODUCTION

The field of psychology, like many other scientific disciplines, is currently facing a replication crisis, in which researchers are struggling to replicate existing findings. In 2015, a group of 270 psychological researchers attempted to replicate the findings of 100 psychology experiments. Whilst 97% of the original studies generated statistically significant findings, only 36% of the replication attempts were statistically significant. In addition, the replicated effects were, on average, half the size of the original effects [@open2015estimating]. These findings illustrate the challenge of replicability in psychological research and the pressing need to rectify flawed research practices. 

One strategy that has been used to combat the replication crisis within psychology is open science. Open science practices are those that increase the transparency of, and access to, scientific research [@klein2018practical]. Open data and open materials practices, for example, involve researchers sharing their raw data and experimental materials on publicly accessible online repositories. These practices make it easier for others to replicate the methodology and reproduce the results from published work [@klein2018practical].  
 
To encourage researchers to employ open science practices, many psychology journals have implemented incentives, like Open Science Badges. In 2013, the Center for Open Science established three Open Science Badges: Open Data, Open Materials and Preregistered, to acknowledge and reward researchers for their use of open science practices (Center for Open Science, 2021). The Open Data Badge and the Open Materials Badge are awarded when the data and materials that are required to reproduce the methods and results of a study are shared publicly online, whilst the Preregistered Badge is awarded when the design,  hypotheses and/or analysis plan are publicly archived prior to data collection. To date, 75 journals (40 in Psychology) have adopted the COS Open Science badges (Center for Open Science, 2021).  

At *Psychological Science*, the Association of Psychological Science’s flagship journal, Open Science Badges appear to have been successful in encouraging researchers to adopt open science practices. In 2016, Kidwell et al. coded the frequency of data and material sharing in the 18 months before and after Open Science Badges were implemented at *Psychological Science*.  [@kidwell2016badges]. Kidwell et al. found that data sharing increased dramatically from 2.5% prior to badges to 39.4% following badges. Materials sharing also rose from 12.7% to 30.3%. Data and material sharing in control journals, such as the *Journal of Personality and Social Psychology*, which did not award badges, remained low over the same time period [@kidwell2016badges]. These results led Kidwell et al. to conclude that Open Science Badges successfully incentivise the uptake of open science practices.  

The support for open science continues to grow, however, it is not yet clear whether engagement with open science is consistent across different fields within psychology. Notably, developmental psychology has received significant criticism for its lack of receptivity towards open science. As Figure 1 illustrates, prominent developmental researchers, Prof Michael Frank and Dr. Jennifer Pfeifer, have labelled the Society for Research in Child Development’s (SRCD) open science policy as ‘weak’ and as one that ‘undervalues openness.’ More recently, the Editor-in-Chief of Infant and Child Development, Prof Moin Syed, stated that the uptake of open science within the field of developmental psychology has been ‘slow and uneven’ [@syed2020infant]. A survey supporting these viewpoints showed that, on average, 80% of researchers publishing in *Child Development* felt their institutions failed to provide adequate guidance or financial support for sharing data, (SRCD Task Force on Scientific Integrity and Openness Survey (2017), cited in Gennetian et al., [@gennetian2020advancing]. As such, developmental researchers may be slower to adopt open science practices than those in other psychological disciplines, however, this possibility has yet to be empirically investigated. 


FIGURE 1

```{r eval = FALSE}
knitr::include_graphics(here::here("Manuscript", "Figure1_mf.png"))
```
```{r eval = FALSE}
knitr::include_graphics(here::here("Manuscript", "Figure1_jp.png"))
```

Meta-research, the study of research itself, can empirically assess whether developmental psychology is truly behind in the open science movement. Previous investigations, including Kidwell et al. [@kidwell2016badges], have revealed that open science incentives can increase the use of open science practices. However, what remains unclear is whether the uptake of open science has been consistent across psychological subfields and sustained over time. To address this research question, we used the open data from the Kidwell et al. study to examine whether rates of data and material sharing, following the implementation of Open Science Badges at Psychological Science, differed as a function of subfield. In addition, we conducted the same open data and materials coding for articles published in the most recent 18 months (July 2019-Dec 2020) to test whether the badges have continued to be impactful and whether the impact has been consistent across subfields. We were particularly interested in determining whether developmental psychology researchers papers published in developmental  impact of badges has beenrovement  sharing practices in the Whilst we expected to observe subfield differences in the use of open science practices, the nature and magnitude of these differences remained unclear. Study 1A was preregistered at the Open Science Framework: https://osf.io/3tsmy/.  

 


# Methods
We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

## Participants

## Material

## Procedure

## Data analysis
We used `r cite_r("r-references.bib")` for all our analyses.


# 1A Results

```{r 1Aprep, message=FALSE, warning=FALSE, include=FALSE}

# read Study1A data

options(scipen=999) # remove scientific notation

data1A <- read_csv(here("Data_Files", "Scored Study 1A Master Dataset.csv"))


# subfield prep
# Assign articles to a subfield group, behNS, cogNS, health and perception grouped together into "Other"
subfield_groups_A <- data1A %>%
  mutate(subfield_groups = case_when(subfield == "Behavioural Neuroscience" ~ "Other",
                                     subfield == "Cognitive Neuroscience" ~ "Other",
                                     subfield == "Health Psychology" ~ "Other",
                                     subfield == "Perception" ~ "Other",
                                     subfield == "Developmental Psychology" ~ "Development",
                                     subfield == "Social Psychology" ~  "Social",
                                      subfield == "Cognition" ~  "Cognition",
                                     TRUE ~ as.character(subfield))) %>%
  relocate(subfield_groups, .after = subfield) %>%
  select(-subfield) # drop original subfield column

# Subfield summary, count articles in each of the 4 subfield groups

subfield_summary_A <- subfield_groups_A %>%
    count(subfield_groups) 

subfield_summary_A

# Time prep
# Group the data in 3 six months: first half of 2014, second half of 2014 and first half of 2015

dates_A <- subfield_groups_A %>%
  mutate(time_period = case_when(
    str_detect(article_id_number, "1-2014|2-2014|3-2014|4-2014|5-2014|6-2014") ~ "1st half 2014",
    str_detect(article_id_number, "7-2014|8-2014|9-2014|10-2014|11-2014|12-2014") ~ "2nd half 2014",
    str_detect(article_id_number, "1-2015|2-2015|3-2015|4-2015|5-2015") ~ "1st half 2015")) %>%
  relocate(time_period, .after = article_id_number)

# Timeperiod summary

timeperiod_summary_A <- dates_A %>%
  count(time_period)

timeperiod_summary_A

# Timeperiod and subfield summary

timeperiod_subfield_summary_A <- dates_A %>%
  tabyl(subfield_groups, time_period) %>%
  select("subfield_groups", "1st half 2014", "2nd half 2014", "1st half 2015")

timeperiod_subfield_summary_A

## Select relevant data for ANOVA analysis

final1A <- dates_A %>%
  select(article_id_number, subfield_groups, time_period, open_data_score, open_materials_score)

# Setting subfield and timeperiod variables as factors 

final1A$subfield_groups <- fct_relevel(final1A$subfield_groups, c("Development", "Social", "Cognition", "Other"))
final1A$time_period <- fct_relevel(final1A$time_period, c("1st half 2014", "2nd half 2014", "1st half 2015"))

```


```{r 1A-d-anova, echo=FALSE, message=FALSE, warning=FALSE}
## DATA ANOVA Analysis 

data_aov_A <- aov_ez(
  data = final1A, dv = "open_data_score", 
  id = "article_id_number", 
  between = c("time_period", "subfield_groups"), 
  type = "2")

data_apa_A <- apa_print(data_aov_A)

```


```{r 1A-d-ttests, echo=FALSE}
## SUBFIELD T-TESTS
### DATA 
# Subfield main effect for Open Data Scores was not significant, so no t-tests to run here

## TIME T-TESTS
### DATA
#### First half 2014 vs. Second half 2014
first2014_second2014 <- final1A %>%
  filter(time_period %in% c("1st half 2014", "2nd half 2014"))

ttest_apa4_A <- apa_print(t_test(open_data_score ~ time_period, first2014_second2014, paired = FALSE))

#### Second half 2014 vs. First half 2015
second2014_first2015 <- final1A %>%
  filter(time_period %in% c("2nd half 2014", "1st half 2015"))

ttest_apa5_A <- apa_print(t_test(open_data_score ~ time_period, second2014_first2015, paired = FALSE))

#### First half 2014 vs. First half 2015
first2014_first2015 <- final1A %>%
  filter(time_period %in% c("1st half 2014", "1st half 2015"))

ttest_apa6_A <- apa_print(t_test(open_data_score ~ time_period, first2014_first2015, paired = FALSE))

```


# 1AData scores text

As illustrated in Figure 1, the two-way between-subjects ANOVA generated a significant main effect of time period, `r data_apa_A$full$time_period`. However, the main effect of subfield, `r data_apa_A$full$subfield_groups`, and the interaction between time period and subfield, `r data_apa_A$full$time_period_subfield_groups`, were not statistically significant. Articles published in the latter part of 2014 had significantly higher open data scores than article published in the first half of the year, `r ttest_apa4_A$statistic`, however there was no further increase across the early part of 2015,`r ttest_apa5_A$statistic`. Critically, there was no significant difference in the open data scores as a function of subfield (see Figure 1a). 


```{r 1A-d-plots, echo=FALSE, message=FALSE, warning=FALSE}

## PLOTS
### DATA
#### Subfield x Data Score
data_subfield_descriptives_A <- final1A %>%
  group_by(subfield_groups) %>%
  summarise(mean_data_score = mean(open_data_score, na.rm = TRUE),
            SD = sd(open_data_score, na.rm = TRUE),
            N = n(),
            stderr = SD/sqrt(N))

d1_A <- data_subfield_descriptives_A %>%
  ggplot(aes(x = subfield_groups, y = mean_data_score, fill = subfield_groups)) +
  geom_col() +
  geom_errorbar(aes(ymin = mean_data_score - stderr, ymax = mean_data_score + stderr), # specifying what the standard error is
                size=.3, # thinner lines
                width=.2) + # narrower bars
    theme_classic() +
    scale_fill_manual(values=c("#EC407A","#42A5F5", "#FFCC33", "#00CC99")) +
  scale_y_continuous(limits = c(0,25), expand = c(0,0)) + # getting the bars to start at the bottom of the graph
  easy_remove_legend() +
  easy_all_text_size(size = 8) + # change the size of the text
  easy_labs(x = "Subfield", y = "Mean Open Data Score") + # change the x and y labels
  ggtitle('(a)')

#### Time Period x Data Score
data_timeperiod_descriptives_A <- final1A %>%
  group_by(time_period) %>%
  summarise(mean_data_score = mean(open_data_score, na.rm = TRUE),
            SD = sd(open_data_score, na.rm = TRUE),
            N = n(),
            stderr = SD/sqrt(N))

# Specifying which levels of the time variable the significance bars need to compare
d2_A_comparisons <- list( c("1st half 2014", "2nd half 2014"), c("2nd half 2014", "1st half 2015"), c("1st half 2014", "1st half 2015") )


d2_A <- data_timeperiod_descriptives_A %>%
  ggplot(aes(x = time_period, y = mean_data_score, fill = time_period)) +
  geom_col() +
  geom_errorbar(aes(ymin = mean_data_score - stderr, ymax = mean_data_score + stderr), # specifying what the standard error is
                size=.3, # thinner lines
                width=.2) + # narrower bars
    theme_classic() +
    scale_fill_manual(values=c("#FFCCCC","#FF9999", "#FF6666")) +
  scale_y_continuous(limits = c(0,25), expand = c(0,0)) + # getting the bars to start at the bottom of the graph
  easy_remove_legend() +
  easy_all_text_size(size = 8) + # change the size of the text
  easy_labs(x = "Time Period", y = "Mean Open Data Score") + # change the x and y labels
  ggtitle('(b)') +
  geom_signif(comparisons = d2_A_comparisons, y_position = c(8, 11, 14), tip_length = 0.1, annotation = c("*", "n.s.", "*"), textsize = 3.5, vjust = -0.3) # adding significance bars


### Interaction between time and subfield - Data scores 
data_subfieldtime_descriptives_A <- final1A %>%
  group_by(subfield_groups, time_period) %>%
  summarise(mean_data_score = mean(open_data_score, na.rm = TRUE),
            SD = sd(open_data_score, na.rm = TRUE),
            N = n(),
            stderr = SD/sqrt(N))


d3_A <- data_subfieldtime_descriptives_A  %>%
  ggplot(aes(x = subfield_groups, y = mean_data_score, fill = time_period)) +
  geom_col(position = "dodge") +
  geom_errorbar(aes(ymin = mean_data_score - stderr, ymax = mean_data_score + stderr), # specifying what the standard error is
                size=.3, # thinner lines
                width=.2, # narrower bars
                position=position_dodge(.9))  +
    theme_classic() +
    scale_fill_manual(values=c("#FFCCCC","#FF9999", "#FF6666")) +
  scale_y_continuous(limits = c(0,25), expand = c(0,0)) + # getting the bars to start at the bottom of the graph
  easy_all_text_size(size = 9) + # change the size of the text
  easy_labs(x = "Subfield", y = "Mean Open Data Score") + # change the x and y labels
  theme(legend.title = element_blank()) + # remove legend title
  ggtitle('(c)')

(d1_A | d2_A) / d3_A

```

*Figure 1*: Mean open data scores for article published in 2014 and 2015, as a function of subfield and time period. 


```{r 1A-m-anova, echo=FALSE, message=FALSE, warning=FALSE}

## MATERIALS ANOVA Analysis 

materials_aov_A <- aov_ez(
  data = final1A, dv = "open_materials_score", 
  id = "article_id_number", 
  between = c("time_period", "subfield_groups"), 
  type = "2")

materials_apa_A <- apa_print(materials_aov_A)

apa_table(materials_apa_A$table,
          caption = "Between-subjects ANOVA for Open Materials Scores")
```


```{r 1A-m-ttests}

## SUBFIELD T-TESTS
### MATERIALS
#### Developmental vs. Cognition
devcog_materials_A <- final1A %>%
  filter(subfield_groups %in% c("Development", "Cognition")) 

ttest_apa1_A <- apa_print(t_test(open_materials_score ~ subfield_groups, devcog_materials_A, paired = FALSE))


#### Developmental vs. Social
devsocial_materials_A <- final1A %>%
  filter(subfield_groups %in% c("Development", "Social"))

ttest_apa2_A <- apa_print(t_test(open_materials_score ~ subfield_groups, devsocial_materials_A, paired = FALSE))

#### Developmental vs. Other
devother_materials_A <- final1A %>%
  filter(subfield_groups %in% c("Development", "Other"))

ttest_apa3_A <- apa_print(t_test(open_materials_score ~ subfield_groups, devother_materials_A, paired = FALSE))

### MATERIALS
## TIME T-TESTS

## MATERIALS
### First half 2014 vs. Second half 2014
ttest_apa7_A <- apa_print(t_test(open_materials_score ~ time_period, first2014_second2014, paired = FALSE))


### Second half 2014 vs. First half 2015
ttest_apa8_A <- apa_print(t_test(open_materials_score ~ time_period, second2014_first2015, paired = FALSE))

### First half 2014 vs. First half 2015
ttest_apa9_A <- apa_print(t_test(open_materials_score ~ time_period, first2014_first2015, paired = FALSE))
```

# 1AMaterial scores text

In contrast, for open materials scores, two-way between-subjects ANOVA generated a significant main effect of subfield, `r materials_apa_A$full$subfield_groups`, and a significant main effect of time period, `r materials_apa_A$full$time_period`. However the interaction between time period and subfield, `r materials_apa_A$full$time_period_subfield_groups`, was not statistically significant. Papers in developmental psychology had lower open materials scores than those in both social, `r ttest_apa2_A$statistic`, and cognition, `r ttest_apa1_A$statistic`, but developmental open materials scores did not differ from papers allocated to the other subfield category, `r ttest_apa3_A$statistic`.  Open materials scores increased incrementally across 2014 and 2015; papers published in the first half of 2015 had significantly higher open materials scores than those published in the first half of 2014,`r ttest_apa9_A$statistic`.


```{r 1A-m-plots, echo=FALSE, message=FALSE, warning=FALSE}
### MATERIALS

#### Subfield x Materials Score
materials_subfield_descriptives_A <- final1A %>%
  group_by(subfield_groups) %>%
  summarise(mean_materials_score = mean(open_materials_score, na.rm = TRUE),
            SD = sd(open_data_score, na.rm = TRUE),
            N = n(),
            stderr = SD/sqrt(N))

# Specifying which levels of the subfield variable the significance bars need to compare
m1_A_comparisons <- list(c("Development", "Social"), c("Development", "Cognition"),  c("Development", "Other") )

# Plot

m1_A <- materials_subfield_descriptives_A %>%
  ggplot(aes(x = subfield_groups, y = mean_materials_score, fill = subfield_groups)) +
  geom_col() +
  geom_errorbar(aes(ymin = mean_materials_score - stderr, ymax = mean_materials_score + stderr), # specifying what the standard error is
                size=.3, # thinner lines
                width=.2) + # narrower bars
    theme_classic() +
    scale_fill_manual(values=c("#EC407A","#42A5F5", "#FFCC33", "#00CC99")) +
  scale_y_continuous(limits = c(0,19), expand = c(0,0)) + # getting the bars to start at the bottom of the graph
  easy_remove_legend() +
  easy_all_text_size(size = 8) + # change the size of the text
  easy_labs(x = "Subfield", y = "Mean Open Materials Score") + # change the x and y labels
  ggtitle('(a)') + 
  geom_signif(comparisons = m1_A_comparisons, y_position = c(7, 9.5, 12), tip_length = 0.1, annotation = c("*", "*", "n.s."), textsize = 3.5, vjust = -0.3) # adding significance bars

#### Time Period x Materials Score
materials_timeperiod_descriptives_A <- final1A %>%
  group_by(time_period) %>%
  summarise(mean_materials_score = mean(open_materials_score, na.rm = TRUE),
            SD = sd(open_materials_score, na.rm = TRUE),
            N = n(),
            stderr = SD/sqrt(N))

# Specifying which levels of the time variable the significance bars need to compare
m2_A_comparisons <- list( c("1st half 2014", "2nd half 2014"), c("2nd half 2014", "1st half 2015"), c("1st half 2014", "1st half 2015") )

# Plot

m2_A <- materials_timeperiod_descriptives_A %>%
  ggplot(aes(x = time_period, y = mean_materials_score, fill = time_period)) +
  geom_col() +
  geom_errorbar(aes(ymin = mean_materials_score - stderr, ymax = mean_materials_score + stderr), # specifying what the standard error is
                size=.3, # thinner lines
                width=.2) + # narrower bars
    theme_classic() +
    scale_fill_manual(values=c("#FFCCCC","#FF9999", "#FF6666")) +
  scale_y_continuous(limits = c(0,19), expand = c(0,0)) + # getting the bars to start at the bottom of the graph
  easy_remove_legend() +
  easy_all_text_size(size = 8) + # change the size of the text
  easy_labs(x = "Time Period", y = "Mean Open Materials Score") + # change the x and y labels
  ggtitle('(b)') + 
  geom_signif(comparisons = m2_A_comparisons, y_position = c(7, 9.5, 12), tip_length = 0.1, annotation = c("n.s.", "n.s.", "*"), textsize = 3.5, vjust = -0.3) # adding significance bars


#### Interaction between time and subfield - Materials Score

materials_subfieldtime_descriptives_A <- final1A %>%
  group_by(subfield_groups, time_period) %>%
  summarise(mean_materials_score = mean(open_materials_score, na.rm = TRUE),
            SD = sd(open_materials_score, na.rm = TRUE),
            N = n(),
            stderr = SD/sqrt(N))

# Plot

m3_A <- materials_subfieldtime_descriptives_A  %>%
  ggplot(aes(x = subfield_groups, y = mean_materials_score, fill = time_period)) +
  geom_col(position = "dodge") +
  geom_errorbar(aes(ymin = mean_materials_score - stderr, ymax = mean_materials_score + stderr), # specifying what the standard error is
                size=.3, # thinner lines
                width=.2, # narrower bars
                position=position_dodge(.9)) + 
    theme_classic() +
    scale_fill_manual(values=c("#FFCCCC","#FF9999", "#FF6666")) +
  scale_y_continuous(limits = c(0,19), expand = c(0,0)) + # getting the bars to start at the bottom of the graph
  easy_all_text_size(size = 9) + # change the size of the text
  easy_labs(x = "Subfield", y = "Mean Open Materials Score") + # change the x and y labels
  theme(legend.title = element_blank()) + # remove legend title
  ggtitle('(c)')

(m1_A | m2_A) / m3_A

```

**Figure 2**: Mean open materials scores for articles published in 2014 and 2015, as a function of subfield and time period. 


# 1B Results

```{r 1Bprep, include=FALSE}
# STUDY 1B CONFIRMATORY - 2019-20

## Read in data

data1B <- read_csv(here("Data_Files", "Scored Study 1B Master Dataset.csv"))

## First factor: Subfield
# Assign articles to subfield groups
subfield_groups_B <- data1B %>%
  mutate(subfield_groups = case_when(subfield == "Behavioural Neuroscience" ~ "Other",
                                     subfield == "Cognitive Neuroscience" ~ "Other",
                                     subfield == "Health Psychology" ~ "Other",
                                     subfield == "Perception" ~ "Other",
                                     subfield == "Developmental Psychology" ~ "Development",
                                     subfield == "Social Psychology" ~  "Social",
                                     TRUE ~ as.character(subfield))) %>%
  relocate(subfield_groups, .after = subfield)

# Delete the original subfield column
subfield_groups_B <- subfield_groups_B %>%
  select(-subfield)

# Subfield summary

subfield_summary_B <- subfield_groups_B %>%
    count(subfield_groups) 

## Second factor: Time 

dates_B <- subfield_groups_B %>%
  mutate(time_period = case_when(
    str_detect(article_id_number, "2019-30-7|2019-30-8|2019-30-9|2019-30-10|2019-30-11|2019-30-12") ~ "2nd half 2019",
    str_detect(article_id_number, "2020-31-1|2020-31-2|2020-31-3|2020-31-4|2020-31-5|2020-31-6") ~ "1st half 2020",
    str_detect(article_id_number, "2020-31-7|2020-31-8|2020-31-9|2020-31-10|2020-31-11|2020-31-12") ~ "2nd half 2020")) %>%
  relocate(time_period, .after = article_id_number)

# Timeperiod summary

timeperiod_summary_B <- dates_B %>%
  count(time_period)

# Timeperiod and subfield summary

timeperiod_subfield_summary_B <- dates_B %>%
  tabyl(subfield_groups, time_period) 

# Select only relevant data
final1B <- dates_B %>%
  select(article_id_number, subfield_groups, time_period, open_data_score, open_materials_score)

# Set subfield and timeperiod variables as factors 

final1B$subfield_groups <- fct_relevel(final1B$subfield_groups, c("Development", "Social", "Cognition", "Other"))
final1B$time_period <- fct_relevel(final1B$time_period, c("2nd half 2019", "1st half 2020","2nd half 2020"))
```

```{r 1B-d-anova}
data_aov_B <- aov_ez(
  data = final1B, dv = "open_data_score", 
  id = "article_id_number", 
  between = c("time_period", "subfield_groups"), 
  type = "2")

data_apa_B <- apa_print(data_aov_B)


```

```{r 1B-d-ttests}
## SUBFIELD T-TESTS

### DATA

#### Development vs. Cognition

devcog_data_B <- final1B %>%
  filter(subfield_groups %in% c("Development", "Cognition"))

ttest_apa1_B <- apa_print(t_test(open_data_score ~ subfield_groups, devcog_data_B, paired = FALSE))

#### Development vs. Social

devsocial_data_B <- final1B %>%
  filter(subfield_groups %in% c("Development", "Social"))

ttest_apa2_B <- apa_print(t_test(open_data_score ~ subfield_groups, devsocial_data_B, paired = FALSE))

#### Development vs. Other

devother_data_B <- final1B %>%
  filter(subfield_groups %in% c("Development", "Other"))

ttest_apa3_B <- apa_print(t_test(open_data_score ~ subfield_groups, devother_data_B, paired = FALSE))

## TIME T-TESTS

### DATA

#### Second half 2019 vs. First half 2020

second2019_first2020 <- final1B %>%
  filter(time_period %in% c("2nd half 2019", "1st half 2020"))

ttest_apa7_B <- apa_print(t_test(open_data_score ~ time_period, second2019_first2020, paired = FALSE))

#### First half 2020 vs. Second half 2020

first2020_second2020 <- final1B %>%
  filter(time_period %in% c("1st half 2020", "2nd half 2020"))

ttest_apa8_B <- apa_print(t_test(open_data_score ~ time_period, first2020_second2020, paired = FALSE))

#### Second half 2019 vs. Second half 2020

second2019_second2020 <- final1B %>%
  filter(time_period %in% c("2nd half 2019", "2nd half 2020"))

ttest_apa9_B <- apa_print(t_test(open_data_score ~ time_period, second2019_second2020, paired = FALSE))

```

## 1BData scores text

Consistent with the results from Study 1A, open data scores also increased significantly across 2019 and 2020, `r data_apa_B$full$time_period`, however across this time period, open data scores differed significantly by subfield, `r data_apa_B$full$subfield_groups`. The interaction between time period and subfield, `r data_apa_B$full$time_period_subfield_groups`, was not statistically significant. When we compared the open data scores from papers published in developmental psychology to each of the other subfield categories (Figure 2a), we found that papers in developmental psychology had significantly lower open data scores than papers in cognition, `r ttest_apa1_B$statistic`. The magnitude of open data scores did not differ from papers published in social psychology, `r ttest_apa2_B$statistic` or those that fell into the other category, `r ttest_apa3_B$statistic`. In terms of changes over time, open data scores increased significantly from late 2019 into 2020, `r ttest_apa7_B$statistic`, but were stable across 2020, `r ttest_apa8_B$statistic`.  

```{r 1B-d-plots, echo=FALSE, message=FALSE, warning=FALSE}
## PLOTS
### DATA
### Subfield x Data Score
data_subfield_descriptives_B <- final1B %>%
  group_by(subfield_groups) %>%
  summarise(mean_data_score = mean(open_data_score, na.rm = TRUE),
            SD = sd(open_data_score, na.rm = TRUE),
            N = n(),
            stderr = SD/sqrt(N))

data_subfield_descriptives_B$subfield_groups <- fct_relevel(data_subfield_descriptives_B$subfield_groups, c("Development", "Social", "Cognition", "Other"))


# Specifying which levels of the subfield variable the significance bars need to compare
d1_B_comparisons <- list(c("Development", "Social"), c("Development", "Cognition"),  c("Development", "Other") )

# Plot

d1_B <- data_subfield_descriptives_B %>%
  ggplot(aes(x = subfield_groups, y = mean_data_score, fill = subfield_groups)) +
  geom_col() +
  geom_errorbar(aes(ymin = mean_data_score - stderr, ymax = mean_data_score + stderr), # specifying what the standard error is
                size=.3, # thinner lines
                width=.2) + # narrower bars
    theme_classic() +
    scale_fill_manual(values=c("#EC407A","#42A5F5", "#FFCC33", "#00CC99")) +
  scale_y_continuous(limits = c(0,25), expand = c(0,0)) + # getting the bars to start at the bottom of the graph
  easy_remove_legend() +
  easy_all_text_size(size = 8) + # change the size of the text
  easy_labs(x = "Subfield", y = "Mean Open Data Score") + # change the x and y labels
  ggtitle('(a)') + 
  geom_signif(comparisons = d1_B_comparisons, y_position = c(17, 19.5, 22.5), tip_length = 0.1, annotation = c("n.s.", "*", "n.s."), textsize = 3.5, vjust = -0.3) # adding significance bars

#### Time Period x Data Score
data_timeperiod_descriptives_B <- final1B %>%
  group_by(time_period) %>%
  summarise(mean_data_score = mean(open_data_score, na.rm = TRUE),
            SD = sd(open_data_score, na.rm = TRUE),
            N = n(),
            stderr = SD/sqrt(N))

# Specifying which levels of the time variable the significance bars need to compare
d2_B_comparisons <- list( c("2nd half 2019", "1st half 2020"), c("1st half 2020", "2nd half 2020"), c("2nd half 2019", "2nd half 2020") )

# Plot

d2_B <- data_timeperiod_descriptives_B %>%
  ggplot(aes(x = time_period, y = mean_data_score, fill = time_period)) +
  geom_col() +
  geom_errorbar(aes(ymin = mean_data_score - stderr, ymax = mean_data_score + stderr), # specifying what the standard error is
                size=.3, # thinner lines
                width=.2) + # narrower bars
    theme_classic() +
    scale_fill_manual(values=c("#FFCCCC","#FF9999", "#FF6666")) +
  scale_y_continuous(limits = c(0,25), expand = c(0,0)) + # getting the bars to start at the bottom of the graph
  easy_remove_legend() +
  easy_all_text_size(size = 8) + # change the size of the text
  easy_labs(x = "Time Period", y = "Mean Open Data Score") + # change the x and y labels
  ggtitle('(b)') +
  geom_signif(comparisons = d2_B_comparisons, y_position = c(18, 20, 22.5), tip_length = 0.1,  annotation = c("*", "n.s.", "n.s."), textsize = 3.5, vjust = -0.3) # adding significance bars

#### Interaction between time and subfield - Data scores 

data_subfieldtime_descriptives_B <- final1B %>%
  group_by(subfield_groups, time_period) %>%
  summarise(mean_data_score = mean(open_data_score, na.rm = TRUE),
            SD = sd(open_data_score, na.rm = TRUE),
            N = n(),
            stderr = SD/sqrt(N))

# Plot

d3_B <- data_subfieldtime_descriptives_B  %>%
  ggplot(aes(x = subfield_groups, y = mean_data_score, fill = time_period)) +
  geom_col(position = "dodge") +
  geom_errorbar(aes(ymin = mean_data_score - stderr, ymax = mean_data_score + stderr), # specifying what the standard error is
                size=.3, # thinner lines
                width=.2, # narrower bars
                position=position_dodge(.9)) + 
    theme_classic() +
    scale_fill_manual(values=c("#FFCCCC","#FF9999", "#FF6666")) +
  scale_y_continuous(limits = c(0,25), expand = c(0,0)) + # getting the bars to start at the bottom of the graph
  easy_all_text_size(size = 9) + # change the size of the text
  easy_labs(x = "Subfield", y = "Mean Open Data Score") + # change the x and y labels
  theme(legend.title = element_blank()) + # remove legend title
  ggtitle('(c)')

(d1_B | d2_B) / d3_B

```

*Figure 3*: Mean open data scores for articles published in 2019 and 2020, as a function of subfield and time period. 

```{r 1B-m-anova}

materials_aov_B <- aov_ez(
  data = final1B, dv = "open_materials_score", 
  id = "article_id_number", 
  between = c("time_period", "subfield_groups"), 
  type = "2")

materials_apa_B <- apa_print(materials_aov_B)

apa_table(materials_apa_B$table,
          caption = "Between-subjects ANOVA for Open Materials Scores")
```

```{r 1B-m-ttests}
### MATERIAL

#### Developmental vs. Cognition

devcog_materials_B <- final1B %>%
  filter(subfield_groups %in% c("Development", "Cognition"))

ttest_apa4_B <- apa_print(t_test(open_materials_score ~ subfield_groups, devcog_materials_B, paired = FALSE))

#### Developmental vs. Social

devsocial_materials_B <- final1B %>%
  filter(subfield_groups %in% c("Development", "Social"))

ttest_apa5_B <- apa_print(t_test(open_materials_score ~ subfield_groups, devsocial_materials_B, paired = FALSE))

### Developmental vs. Other

devother_materials_B <- final1B %>%
  filter(subfield_groups %in% c("Development", "Other"))

ttest_apa6_B <- apa_print(t_test(open_materials_score ~ subfield_groups, devother_materials_B, paired = FALSE))

### MATERIALS

# The time period main effect for Open Materials Scores was not statistically significant, so no t-tests to run here

```


## 1BMaterials scores text

As in Study 1A, for open materials scores in 2019 and 2020, there was a significant main effect of subfield, `r materials_apa_B$full$subfield_groups`, however the main effect of time period, `r materials_apa_B$full$time_period`, and the interaction between time period and subfield, `r materials_apa_B$full$time_period_subfield_groups`, were not statistically significant (see Figure 2). Consistent with open data scores, papers published in developmental psychology had significantly lower open materials scores than paper published in cognition, `r ttest_apa4_B$statistic`, however, open materials scores did not differ between developmental and social psychology, `r ttest_apa5_B$statistic`, or between developmental psychology and the other subfield category, `r ttest_apa6_B$statistic`. There were no additional changes in open materials scores across this period between mid-2019 and the end of 2020. 

```{r 1B-m-plots, echo=FALSE, message=FALSE, warning=FALSE}
### MATERIALS
#### Subfield x Materials Score

materials_subfield_descriptives_B <- final1B %>%
  group_by(subfield_groups) %>%
  summarise(mean_materials_score = mean(open_materials_score, na.rm = TRUE),
            SD = sd(open_data_score, na.rm = TRUE),
            N = n(),
            stderr = SD/sqrt(N))
# Specifying which levels of the subfield variable the significance bars need to compare
m1_B_comparisons <- list(c("Development", "Social"), c("Development", "Cognition"),  c("Development", "Other") )

# Plot

m1_B <- materials_subfield_descriptives_B %>%
  ggplot(aes(x = subfield_groups, y = mean_materials_score, fill = subfield_groups)) +
  geom_col() +
  geom_errorbar(aes(ymin = mean_materials_score - stderr, ymax = mean_materials_score + stderr), # specifying what the standard error is
                size=.3, # thinner lines
                width=.2) + # narrower bars
    theme_classic() +
    scale_fill_manual(values=c("#EC407A","#42A5F5", "#FFCC33", "#00CC99")) +
  scale_y_continuous(limits = c(0,19), expand = c(0,0)) + # getting the bars to start at the bottom of the graph
  easy_remove_legend() +
  easy_all_text_size(size = 8) + # change the size of the text
  easy_labs(x = "Subfield", y = "Mean Open Materials Score") + # change the x and y labels
  ggtitle('(a)') + 
  geom_signif(comparisons = m1_B_comparisons, y_position = c(11.5, 14.5, 17), tip_length = 0.1, annotation = c("n.s.", "*", "n.s."), textsize = 3.5, vjust = -0.3) # adding significance bars


#### Time Period x Materials Score

materials_timeperiod_descriptives_B <- final1B %>%
  group_by(time_period) %>%
  summarise(mean_materials_score = mean(open_materials_score, na.rm = TRUE),
            SD = sd(open_materials_score, na.rm = TRUE),
            N = n(),
            stderr = SD/sqrt(N))

# Plot

m2_B <- materials_timeperiod_descriptives_B %>%
  ggplot(aes(x = time_period, y = mean_materials_score, fill = time_period)) +
  geom_col() +
  geom_errorbar(aes(ymin = mean_materials_score - stderr, ymax = mean_materials_score + stderr), # specifying what the standard error is
                size=.3, # thinner lines
                width=.2) + # narrower bars
    theme_classic() +
    scale_fill_manual(values=c("#FFCCCC","#FF9999", "#FF6666")) +
  scale_y_continuous(limits = c(0,19), expand = c(0,0)) + # getting the bars to start at the bottom of the graph
  easy_remove_legend() +
  easy_all_text_size(size = 8) + # change the size of the text
  easy_labs(x = "Time Period", y = "Mean Open Materials Score") + # change the x and y labels
  ggtitle('(b)')

#### Interaction between time and subfield - Materials Score


materials_subfieldtime_descriptives_B <- final1B %>%
  group_by(subfield_groups, time_period) %>%
  summarise(mean_materials_score = mean(open_materials_score, na.rm = TRUE),
            SD = sd(open_materials_score, na.rm = TRUE),
            N = n(),
            stderr = SD/sqrt(N))


# Plot

m3_B <- materials_subfieldtime_descriptives_B  %>%
  ggplot(aes(x = subfield_groups, y = mean_materials_score, fill = time_period)) +
  geom_col(position = "dodge") +
  geom_errorbar(aes(ymin = mean_materials_score - stderr, ymax = mean_materials_score + stderr), # specifying what the standard error is
                size=.3, # thinner lines
                width=.2, # narrower bars
                position=position_dodge(.9)) + 
    theme_classic() +
    scale_fill_manual(values=c("#FFCCCC","#FF9999", "#FF6666")) +
  scale_y_continuous(limits = c(0,19), expand = c(0,0)) + # getting the bars to start at the bottom of the graph
  easy_all_text_size(size = 9) + # change the size of the text
  easy_labs(x = "Subfield", y = "Mean Open Materials Score") + # change the x and y labels
   theme(legend.title = element_blank()) + # remove legend title
  ggtitle('(c)')

(m1_B | m2_B) / m3_B


```

*Figure 4*: Mean open materials scores for articles published in 2019 and 2020, as a function of subfield and time period. 


# AB ACROSS time

```{r ab_prep, include=FALSE}

# STUDY 1B CONFIRMATORY - 2014-15 vs. 2019-20
## Merge 1A and 1B data into one dataframe

alldata <- rbind(final1A, final1B)

## Condense to two levels of time

dates_AB <- alldata %>%
  mutate(time_period = case_when(time_period %in% c("1st half 2014", "2nd half 2014", "1st half 2015") ~ "2014-15", time_period %in% c("2nd half 2019", "1st half 2020", "2nd half 2020") ~ "2019-20"))

# Set subfield and timeperiod variables as factors 

dates_AB$subfield_groups <- fct_relevel(dates_AB$subfield_groups, c("Development", "Social", "Cognition", "Other"))
dates_AB$time_period <- fct_relevel(dates_AB$time_period, c("2014-15", "2019-20"))

# Subfield group and Timeperiod summary

subfield_summary_AB <- dates_AB %>%
    count(subfield_groups) 

timeperiod_summary_AB <- dates_AB %>%
  count(time_period)

```


```{r ab_d-aov, echo=FALSE, message=FALSE, warning=FALSE}

## DATA ANOVA Analysis
data_aov_AB <- aov_ez(
  data = dates_AB, dv = "open_data_score", 
  id = "article_id_number", 
  between = c("time_period", "subfield_groups"), 
  type = "2")

data_apa_AB <- apa_print(data_aov_AB)


# MATERIALS ANOVA analysis
materials_aov_AB <- aov_ez(
  data = dates_AB, dv = "open_materials_score", 
  id = "article_id_number", 
  between = c("time_period", "subfield_groups"), 
  type = "2")

materials_apa_AB <- apa_print(materials_aov_AB)


```


```{r AB-d-plot, echo=FALSE}

## PLOTS
### DATA
#### Subfield x Data Score

data_subfield_descriptives_AB <- dates_AB %>%
  group_by(subfield_groups) %>%
  summarise(mean_data_score = mean(open_data_score, na.rm = TRUE),
            SD = sd(open_data_score, na.rm = TRUE),
            N = n(),
            stderr = SD/sqrt(N))

data_subfield_descriptives_AB$subfield_groups <- fct_relevel(data_subfield_descriptives_AB$subfield_groups, c("Development", "Social", "Cognition", "Other"))

# Specifying which levels of the subfield variable the significance bars need to compare
d1_AB_comparisons <- list(c("Development", "Social"), c("Development", "Cognition"),  c("Development", "Other") )

# Plot

d1_AB <- data_subfield_descriptives_AB %>%
  ggplot(aes(x = reorder(subfield_groups, mean_data_score), y = mean_data_score, fill = subfield_groups)) +
  geom_col() +
  geom_errorbar(aes(ymin = mean_data_score - stderr, ymax = mean_data_score + stderr), # specifying what the standard error is
                size=.3, # thinner lines
                width=.2) + # narrower bars
    theme_classic() +
    scale_x_discrete(limits=c("Development", "Social", "Cognition", "Other")) +
    scale_fill_manual(values=c("#EC407A","#42A5F5", "#FFCC33", "#00CC99")) +
  scale_y_continuous(limits = c(0,25), expand = c(0,0)) + # getting the bars to start at the bottom of the graph
  easy_remove_legend() +
  easy_all_text_size(size = 8) + # change the size of the text
  easy_labs(x = "Subfield", y = "Mean Open Data Score") + # change the x and y labels
  ggtitle('(a)') + 
  geom_signif(comparisons = d1_AB_comparisons, y_position = c(10, 14, 18), tip_length = 0.1, annotation = c("n.s.", "*", "n.s."), textsize = 3.5, vjust = -0.3) # adding significance bars

#### Time Period x Data Score
data_timeperiod_descriptives_AB <- dates_AB %>%
  group_by(time_period) %>%
  summarise(mean_data_score = mean(open_data_score, na.rm = TRUE),
            SD = sd(open_data_score, na.rm = TRUE),
            N = n(),
            stderr = SD/sqrt(N))

# Specifying which levels of the time variable the significance bars need to compare
d2_AB_comparisons <- list( c("2014-15", "2019-20"))

# Plot

d2_AB <- data_timeperiod_descriptives_AB %>%
  ggplot(aes(x = time_period, y = mean_data_score, fill = time_period)) +
  geom_col() +
  geom_errorbar(aes(ymin = mean_data_score - stderr, ymax = mean_data_score + stderr), # specifying what the standard error is
                size=.3, # thinner lines
                width=.2) + # narrower bars
    theme_classic() +
    scale_fill_manual(values=c("#FFCCCC","#FF6666")) +
  scale_y_continuous(limits = c(0,25), expand = c(0,0)) + # getting the bars to start at the bottom of the graph
  easy_remove_legend() +
  easy_all_text_size(size = 8) + # change the size of the text
  easy_labs(x = "Time Period", y = "Mean Open Data Score") + # change the x and y labels
  ggtitle('(b)') +
  geom_signif(comparisons = d2_AB_comparisons, y_position = 17, tip_length = 0.1,  annotation = "*", textsize = 3.5, vjust = -0.3) # adding significance bars

#### Interaction between time and subfield - Data scores 
data_subfieldtime_descriptives_AB <- dates_AB %>%
  group_by(subfield_groups, time_period) %>%
  summarise(mean_data_score = mean(open_data_score, na.rm = TRUE),
            SD = sd(open_data_score, na.rm = TRUE),
            N = n(),
            stderr = SD/sqrt(N))

# Plot

d3_AB <- data_subfieldtime_descriptives_AB  %>%
  ggplot(aes(x = subfield_groups, y = mean_data_score, fill = time_period)) +
  geom_col(position = "dodge") +
  geom_errorbar(aes(ymin = mean_data_score - stderr, ymax = mean_data_score + stderr), # specifying what the standard error is
                size=.3, # thinner lines
                width=.2, # narrower bars
                position=position_dodge(.9)) + 
    theme_classic() +
    scale_fill_manual(values=c("#FFCCCC","#FF6666")) +
  scale_y_continuous(limits = c(0,25), expand = c(0,0)) + # getting the bars to start at the bottom of the graph
  easy_all_text_size(size = 9) + # change the size of the text
  easy_labs(x = "Subfield", y = "Mean Open Data Score") + # change the x and y labels
  theme(legend.title = element_blank()) + # remove legend title
  ggtitle('a) Open Data scores')

```



```{r ab_m-aov, echo=FALSE, message=FALSE, warning=FALSE}

# MATERIALS ANOVA analysis
materials_aov_AB <- aov_ez(
  data = dates_AB, dv = "open_materials_score", 
  id = "article_id_number", 
  between = c("time_period", "subfield_groups"), 
  type = "2")

materials_apa_AB <- apa_print(materials_aov_AB)

```


# AB data/materials text

When looking at open data scores across both time periods, we found that scores increased over time, `r data_apa_AB$full$time_period`, and differed as a function of subfield, `r data_apa_AB$full$subfield_groups`. However, the interaction between time period and subfield, `r data_apa_AB$full$time_period_subfield_groups`, was not statistically significant, suggesting that there were no subfield differences in the magnitude of open data scores over time (see Figure Xa). A similar pattern was found for open material scores; scores increased over time `r materials_apa_AB$full$time_period`, and differed by subfield, `r materials_apa_AB$full$subfield_groups`, but there was no evidence that the magnitude of improvement over time differed by subfield (see Figure Xb), `r materials_apa_AB$full$time_period_subfield_groups`. 

> t-tests probably not necessary, b/c point was really to see if there was an interaction, also maybe the most appropriate plot is just the interaction one, rather than subfield + time

```{r AB-m-plot, echo=FALSE}

### MATERIALS

#### Subfield x Materials Score
materials_subfield_descriptives_AB <- dates_AB %>%
  group_by(subfield_groups) %>%
  summarise(mean_materials_score = mean(open_materials_score, na.rm = TRUE),
            SD = sd(open_materials_score, na.rm = TRUE),
            N = n(),
            stderr = SD/sqrt(N))

# Specifying which levels of the subfield variable the significance bars need to compare
m1_AB_comparisons <- list(c("Development", "Social"), c("Development", "Cognition"),  c("Development", "Other") )

# Plot

m1_AB <- materials_subfield_descriptives_AB %>%
  ggplot(aes(x = subfield_groups, y = mean_materials_score, fill = subfield_groups)) +
  geom_col() +
  geom_errorbar(aes(ymin = mean_materials_score - stderr, ymax = mean_materials_score + stderr), # specifying what the standard error is
                size=.3, # thinner lines
                width=.2) + # narrower bars
    theme_classic() +
    scale_fill_manual(values=c("#EC407A","#42A5F5", "#FFCC33", "#00CC99")) +
  scale_y_continuous(limits = c(0,19), expand = c(0,0)) + # getting the bars to start at the bottom of the graph
  easy_remove_legend() +
  easy_all_text_size(size = 8) + # change the size of the text
  easy_labs(x = "Subfield", y = "Mean Open Materials Score") + # change the x and y labels
  ggtitle('(a)') + 
  geom_signif(comparisons = m1_AB_comparisons, y_position = c(7.5, 10.5, 13.5), tip_length = 0.1, annotation = c("*", "*", "n.s."), textsize = 3.5, vjust = -0.3) # adding significance bars

#### Time Period x Materials Score

materials_timeperiod_descriptives_AB <- dates_AB %>%
  group_by(time_period) %>%
  summarise(mean_materials_score = mean(open_materials_score, na.rm = TRUE),
            SD = sd(open_materials_score, na.rm = TRUE),
            N = n(),
            stderr = SD/sqrt(N))

# Specifying which levels of the time variable the significance bars need to compare
m2_AB_comparisons <- list( c("2014-15", "2019-20"))

# Plot

m2_AB <- materials_timeperiod_descriptives_AB %>%
  ggplot(aes(x = time_period, y = mean_materials_score, fill = time_period)) +
  geom_col() +
  geom_errorbar(aes(ymin = mean_materials_score - stderr, ymax = mean_materials_score + stderr), # specifying what the standard error is
                size=.3, # thinner lines
                width=.2) + # narrower bars
    theme_classic() +
    scale_fill_manual(values=c("#FFCCCC","#FF6666")) +
  scale_y_continuous(limits = c(0,19), expand = c(0,0)) + # getting the bars to start at the bottom of the graph
  easy_remove_legend() +
  easy_all_text_size(size = 8) + # change the size of the text
  easy_labs(x = "Time Period", y = "Mean Open Materials Score") + # change the x and y labels
  ggtitle('(b)') +
  geom_signif(comparisons = m2_AB_comparisons, y_position = 11, tip_length = 0.1,  annotation = "*", textsize = 3.5, vjust = -0.3) # adding significance bars

#### Interaction between time and subfield - Materials Score

materials_subfieldtime_descriptives_AB <- dates_AB %>%
  group_by(subfield_groups, time_period) %>%
  summarise(mean_materials_score = mean(open_materials_score, na.rm = TRUE),
            SD = sd(open_materials_score, na.rm = TRUE),
            N = n(),
            stderr = SD/sqrt(N))

# Plot

m3_AB <- materials_subfieldtime_descriptives_AB  %>%
  ggplot(aes(x = subfield_groups, y = mean_materials_score, fill = time_period)) +
  geom_col(position = "dodge") +
  geom_errorbar(aes(ymin = mean_materials_score - stderr, ymax = mean_materials_score + stderr), # specifying what the standard error is
                size=.3, # thinner lines
                width=.2, # narrower bars
                position=position_dodge(.9)) + 
    theme_classic() +
    scale_fill_manual(values=c("#FFCCCC","#FF6666")) +
  scale_y_continuous(limits = c(0,19), expand = c(0,0)) + # getting the bars to start at the bottom of the graph
  easy_all_text_size(size = 9) + # change the size of the text
  easy_labs(x = "Subfield", y = "Mean Open Materials Score") + # change the x and y labels
    theme(legend.title = element_blank()) + # remove legend title
  ggtitle('b) Open Materials scores')

#(m1_AB | m2_AB) / m3_AB

d3_AB / m3_AB

```

> including just the combo of interaction plots here. Christina- can you remove the code that makes the subfield and time plots from the chunks above and work out how to make this patchwork plot share y axis labels and legends


> JENNY UP TO HERE 

# STUDY 1B EXPLORATORY

## RAINCLOUD PLOTS

```{r 1ab-rain, echo=FALSE}

### 1A Data Plot
# Note: We tried using the raincloud package function, but it only allowed us to compare two subfields at a time

rainplot_data1 <- final1A %>%  
  ggplot(aes(x = subfield_groups, y = open_data_score, fill = subfield_groups)) +
  geom_flat_violin(position = position_nudge(x = 0.025, y = 0),adjust = 0.5, alpha = 0.5) +
  geom_half_point(alpha = .3, size = 1, range_scale = 1, position = position_nudge(x = -0.4, y = 0)) +
    theme_classic() +
    theme(axis.title.y = element_text(size=9)) +
  scale_fill_manual(values=c("#EC407A","#42A5F5", "#FFCC33", "#00CC99")) +
  scale_x_discrete(labels=c("Development" = "Development\n(n = 65)","Social" = "Social\n(n = 91)","Cognition" = "Cognition\n(n = 91)","Other" = "Other\n(n = 75)")) +
  labs(x = element_blank(), y = 'Open Data Score') +
  easy_remove_legend() + 
  ggtitle('(a)')

### 1A Materials Plot
rainplot_materials1 <- final1A %>%  
  ggplot(aes(x = subfield_groups, y = open_materials_score, fill = subfield_groups)) +
  geom_flat_violin(position = position_nudge(x = 0.025, y = 0),adjust = 0.5, alpha = 0.5) +
  geom_half_point(alpha = .3, size = 1, range_scale = 1, position = position_nudge(x = -0.4, y = 0)) +
    theme_classic() +
    theme(axis.title.y = element_text(size=9)) +
  scale_fill_manual(values=c("#EC407A","#42A5F5", "#FFCC33", "#00CC99")) +
  scale_x_discrete(labels=c("Development" = "Development\n(n = 65)","Social" = "Social\n(n = 91)","Cognition" = "Cognition\n(n = 91)","Other" = "Other\n(n = 75)")) +
  labs(x = element_blank(), y = 'Open Materials Score') +
  easy_remove_legend() + 
  ggtitle('(b)')

### 1B Data Plot
rainplot_data2 <- final1B %>%  
  ggplot(aes(x = subfield_groups, y = open_data_score, fill = subfield_groups)) +
  geom_flat_violin(position = position_nudge(x = 0.025, y = 0),adjust = 0.5, alpha = 0.5) +
  geom_half_point(alpha = .3, size = 1, range_scale = 1, position = position_nudge(x = -0.4, y = 0)) +
    theme_classic() +
    theme(axis.title.y = element_text(size=9)) +
  scale_fill_manual(values=c("#EC407A","#42A5F5", "#FFCC33", "#00CC99")) +
  scale_x_discrete(labels=c("Development" = "Development\n(n = 34)","Social" = "Social\n(n = 57)","Cognition" = "Cognition\n(n = 61)","Other" = "Other\n(n = 41)")) +
  labs(x = element_blank(), y = 'Open Data Score') +
  easy_remove_legend() + 
  ggtitle('(c)')

### 1B Materials Plot

rainplot_materials2 <- final1B %>%  
  ggplot(aes(x = subfield_groups, y = open_materials_score, fill = subfield_groups)) +
  geom_flat_violin(position = position_nudge(x = 0.025, y = 0),adjust = 0.5, alpha = 0.5) +
  geom_half_point(alpha = .3, size = 1, range_scale = 1, position = position_nudge(x = -0.4, y = 0)) +
    theme_classic() +
  theme(axis.title.y = element_text(size=9)) +
  scale_fill_manual(values=c("#EC407A","#42A5F5", "#FFCC33", "#00CC99")) +
  scale_x_discrete(labels=c("Development" = "Development\n(n = 34)","Social" = "Social\n(n = 57)","Cognition" = "Cognition\n(n = 61)","Other" = "Other\n(n = 41)")) +
  labs(x = element_blank(), y = 'Open Materials Score') +
  easy_remove_legend() + 
  ggtitle('(d)')

### patch figure 

(rainplot_data1 | rainplot_materials1) / 
(rainplot_data2 | rainplot_materials2)
```

## OPEN SCIENCE BADGES


```{r osb-prep, message=FALSE, warning=FALSE, include=FALSE}

### Open Data Badge Plot
#### Select only relevant 1A variables

A_select_data <- subfield_groups_A  %>%
  select(article_id_number, subfield_groups, did_the_article_receive_a_badge_for_open_data, data_statement_indicates_that_data_are, are_the_data_located_at_the_working_page, does_the_data_correspond_to_what_is_reported_in_the_article, software, is_a_codebook_included_with_the_data_or_other_means_of_understanding_the_variables, are_analysis_scripts_included_with_the_data, are_the_data_complete)

# Percentage of articles that received a badge
A_data_badge <- A_select_data %>%
  tabyl(did_the_article_receive_a_badge_for_open_data)

#### Summary tables
# reportedly available
A_reportedly_available_data <- A_select_data %>%
  filter(did_the_article_receive_a_badge_for_open_data == "Yes") %>%
  tabyl(did_the_article_receive_a_badge_for_open_data, data_statement_indicates_that_data_are) %>%
  mutate("Percent" = Available/(Available)*100) %>%
  select(Number = Available, Percent) %>%
  mutate(Real_Stage = "Reportedly Available")

# locatable data
A_locatable_data <- A_select_data %>%
  filter(did_the_article_receive_a_badge_for_open_data == "Yes") %>%
  tabyl(did_the_article_receive_a_badge_for_open_data, are_the_data_located_at_the_working_page) %>%
  mutate("Percent" = Yes/(Yes)*100) %>%
  select(Number = Yes, Percent) %>%
  mutate(Real_Stage = "Actually Locatable")

# correct data 
A_correct_data <- A_select_data %>%
  filter(did_the_article_receive_a_badge_for_open_data == "Yes") %>%
  tabyl(did_the_article_receive_a_badge_for_open_data, does_the_data_correspond_to_what_is_reported_in_the_article) %>%
  mutate("Percent" = Yes/(Yes + Unclear)*100) %>%
  select(Number = Yes, Percent) %>%
  mutate(Real_Stage = "Correct Data")

# complete data
A_complete_data <- A_select_data %>%
  filter(did_the_article_receive_a_badge_for_open_data == "Yes") %>%
  tabyl(did_the_article_receive_a_badge_for_open_data, are_the_data_complete) %>%
  mutate("Percent" = `Yes, all of the data appear to be available`/(`Yes, all of the data appear to be available` + `Yes, but only some of the data are available` + `No, not all of the data are available` + `Unclear whether or not all of the data are available`)*100) %>%
  select(Number = `Yes, all of the data appear to be available`, Percent) %>%
  mutate(Real_Stage = "Complete Data")

# software specified
A_software_specified <- A_select_data %>%
  filter(did_the_article_receive_a_badge_for_open_data == "Yes") %>%
  tabyl(did_the_article_receive_a_badge_for_open_data, software) %>%
  mutate("Percent" = Yes/(Yes + No)*100) %>%
  select(Number = Yes, Percent) %>%
  mutate(Real_Stage = "Software Specified")

# codebook available 
A_data_codebook_available <- A_select_data %>%
  filter(did_the_article_receive_a_badge_for_open_data == "Yes") %>%
  tabyl(did_the_article_receive_a_badge_for_open_data, is_a_codebook_included_with_the_data_or_other_means_of_understanding_the_variables) %>%
  mutate("Percent" = Yes/(Yes + No)*100) %>%
  select(Number = Yes, Percent) %>%
  mutate(Real_Stage = "Codebook Available")

# scripts available 
A_data_scripts_available <- A_select_data %>%
  filter(did_the_article_receive_a_badge_for_open_data == "Yes") %>%
  tabyl(did_the_article_receive_a_badge_for_open_data, are_analysis_scripts_included_with_the_data) %>%
  mutate("Percent" = Yes/(Yes + No)*100) %>%
  select(Number = Yes, Percent) %>%
  mutate(Real_Stage = "Scripts Available")
```

#### Bind all statistics together
```{r echo=FALSE, message=FALSE, warning=FALSE}

A_data_stats <- rbind(A_reportedly_available_data, A_locatable_data, A_correct_data, A_complete_data, A_software_specified, A_data_codebook_available, A_data_scripts_available)

A_data_stats <- A_data_stats %>%
  mutate("Time" = "2014-15") 
```

#### Select only relevant 1B variables
```{r message=FALSE, warning=FALSE, include=FALSE}

B_select_data <- subfield_groups_B  %>%
  select(article_id_number, subfield_groups, data_badge, data_statement_indicates, data_locatable, data_correspond, software, data_codebook, data_scripts, data_complete)

# Percentage of articles that received a badge
B_data_badge <- B_select_data %>%
  tabyl(data_badge)

```

#### Summary tables

```{r message=FALSE, warning=FALSE, include=FALSE}

# reportedly available
B_reportedly_available_data <- B_select_data %>%
  filter(data_badge == "Yes") %>%
  tabyl(data_badge, data_statement_indicates) %>%
  mutate("Percent" = Available/(Available + Unavailable)*100) %>%
  select(Number = Available, Percent) %>%
  mutate(Real_Stage = "Reportedly Available")

# locatable data
B_locatable_data <- B_select_data %>%
  filter(data_badge == "Yes") %>%
  tabyl(data_badge, data_locatable) %>%
  mutate("Percent" = Yes/(Yes + No + `Requires permission`)*100) %>%
  select(Number = Yes, Percent) %>%
  mutate(Real_Stage = "Actually Locatable")

# correct data 
B_correct_data <- B_select_data %>%
  filter(data_badge == "Yes") %>%
  tabyl(data_badge, data_correspond) %>%
  mutate("Percent" = Yes/(Yes + Unclear)*100) %>%
  select(Number = Yes, Percent) %>%
  mutate(Real_Stage = "Correct Data")

# complete data
B_complete_data <- B_select_data %>%
  filter(data_badge == "Yes") %>%
  tabyl(data_badge, data_complete) %>%
  mutate("Percent" = `Yes, all of the data appear to be available`/(`Yes, all of the data appear to be available` + `Yes, but only some of the data are available` + `Unclear whether or not all the data are available`)*100) %>%
  select(Number = `Yes, all of the data appear to be available`, Percent) %>%
  mutate(Real_Stage = "Complete Data")

# software specified
B_software_specified <- B_select_data %>%
  filter(data_badge == "Yes") %>%
  tabyl(data_badge, software) %>%
  mutate("Percent" = Yes/(Yes + No)*100) %>%
  select(Number = Yes, Percent) %>%
  mutate(Real_Stage = "Software Specified")

# codebook available 
B_data_codebook_available <- B_select_data %>%
  filter(data_badge == "Yes") %>%
  tabyl(data_badge, data_codebook) %>%
  mutate("Percent" = Yes/(Yes + No)*100) %>%
  select(Number = Yes, Percent) %>%
  mutate(Real_Stage = "Codebook Available")

# scripts available 
B_data_scripts_available <- B_select_data %>%
  filter(data_badge == "Yes") %>%
  tabyl(data_badge, data_scripts) %>%
  mutate("Percent" = Yes/(Yes + No)*100) %>%
  select(Number = Yes, Percent) %>%
  mutate(Real_Stage = "Scripts Available")

#### Bind all statistics together

B_data_stats <- rbind(B_reportedly_available_data, B_locatable_data, B_correct_data, B_complete_data, B_software_specified, B_data_codebook_available, B_data_scripts_available)

B_data_stats <- B_data_stats %>%
  mutate("Time" = "2019-20") 

```

#### Combine 1A and 1B stats together
```{r combo-data, include=FALSE}

all_data_stats <- rbind(A_data_stats, B_data_stats)
```

#### Plot combined data
```{r combo-plot, echo=FALSE}

combined_data_plot <- ggplot(all_data_stats, aes(y=Percent,  group = Time, colour = Time)) +
  coord_cartesian(ylim=c(0,100)) +
  geom_line(aes(colour=Time, x=Real_Stage), size = 1) +
  geom_point(aes(x=Real_Stage), size=3, position = position_dodge(width=0)) +
    scale_color_manual(values=c("#EC407A","#42A5F5"),
                     labels=c("2014-15 (n = 46)",
                              "2019-20 (n = 133)")) +
  theme(axis.text.y = element_text(size=9),
        axis.title.y = element_text(size=9)) +
  theme(axis.text.x = element_text(size=7),
        axis.title.x = element_text(size=9, margin = margin(t = 8, r = 0, b = 0, l = 0))) +
  easy_labs(y = "Percentage of Articles That Received an Open Data Badge", x = "Data Sharing Criteria") +
  scale_x_discrete(limits=c("Reportedly Available","Actually Locatable","Correct Data","Complete Data", "Codebook Available", "Software Specified", "Scripts Available")) +
    theme(legend.position=c(0.2, .3)) +
  theme(legend.title=element_blank()) +
  theme(legend.text = element_text(size = 9)) +
  theme(legend.key.size = unit(1, "cm")) +
  theme(axis.line= element_line(), 
        panel.background = element_blank(), 
        panel.grid.minor = element_blank()) 

combined_data_plot

```


```{r omb-prep, message=FALSE, warning=FALSE, include=FALSE}
### Open Materials Badge Plot
#### Select only relevant 1A variables
A_select_materials <- subfield_groups_A %>%
  select(article_id_number, subfield_groups, did_the_article_receive_a_badge_for_open_materials, statement_indicates_that_materials_are, are_the_materials_located_at_the_working_page, do_the_materials_correspond_to_what_is_reported_in_the_article, are_the_materials_complete, are_analysis_scripts_included_with_the_materials)

# Percentage of articles that received a badge
A_materials_badge <- A_select_materials %>%
  tabyl(did_the_article_receive_a_badge_for_open_materials)
```


```{r message=FALSE, warning=FALSE, include=FALSE}
#### Summary tables
# reportedly available
A_reportedly_available_materials <- A_select_materials %>%
  filter(did_the_article_receive_a_badge_for_open_materials == "Yes") %>%
  tabyl(did_the_article_receive_a_badge_for_open_materials, statement_indicates_that_materials_are) %>%
  mutate("Percent" = Available/(Available)*100) %>%
  select(Number = Available, Percent) %>%
  mutate(Real_Stage = "Reportedly Available")

# locatable materials
A_locatable_materials <- A_select_materials %>%
  filter(did_the_article_receive_a_badge_for_open_materials == "Yes") %>%
  tabyl(did_the_article_receive_a_badge_for_open_materials, are_the_materials_located_at_the_working_page) %>%
  mutate("Percent" = Yes/(Yes)*100) %>%
  select(Number = Yes, Percent) %>%
  mutate(Real_Stage = "Actually Locatable")

# correct materials
A_correct_materials <- A_select_materials %>%
  filter(did_the_article_receive_a_badge_for_open_materials == "Yes") %>%
  tabyl(did_the_article_receive_a_badge_for_open_materials, do_the_materials_correspond_to_what_is_reported_in_the_article) %>%
  mutate("Percent" = Yes/(Yes)*100) %>%
  select(Number = Yes, Percent) %>%
  mutate(Real_Stage = "Correct Materials")

# complete materials
A_complete_materials <- A_select_materials %>%
  filter(did_the_article_receive_a_badge_for_open_materials == "Yes") %>%
  tabyl(did_the_article_receive_a_badge_for_open_materials, are_the_materials_complete) %>%
  mutate("Percent" = `Yes, all of the materials appear to be available`/(`Yes, all of the materials appear to be available` + `Yes, but only some of the materials are available` + `No, not all of the materials are available`)*100) %>%
  select(Number = `Yes, all of the materials appear to be available`, Percent) %>%
  mutate(Real_Stage = "Complete Materials")

# scripts available 
A_material_scripts_available <- A_select_materials %>%
  filter(did_the_article_receive_a_badge_for_open_materials == "Yes") %>%
  tabyl(did_the_article_receive_a_badge_for_open_materials, are_analysis_scripts_included_with_the_materials) %>%
  mutate("Percent" = Yes/(Yes + No)*100) %>%
  select(Number = Yes, Percent) %>%
  mutate(Real_Stage = "Scripts Available/\nExplanation Provided")

#### Bind all statistics
A_material_stats <- rbind(A_reportedly_available_materials, A_locatable_materials, A_correct_materials, A_complete_materials, A_material_scripts_available)

A_material_stats <- A_material_stats %>%
  mutate("Time" = "2014-15") 

#### Select only relevant 1Bvariables

B_select_materials <- subfield_groups_B %>%
  select(article_id_number, subfield_groups, materials_badge, materials_statement_indicates, materials_locatable, materials_correspond, materials_complete, materials_explanation)

# Percentage of articles that received a badge
B_materials_badge <- B_select_materials %>%
  tabyl(materials_badge)

#### Summary tables
# reportedly available
B_reportedly_available_materials <- B_select_materials %>%
  filter(materials_badge == "Yes") %>%
  tabyl(materials_badge, materials_statement_indicates) %>%
  mutate("Percent" = Available/(Available)*100) %>%
  select(Number = Available, Percent) %>%
  mutate(Real_Stage = "Reportedly Available")

# locatable materials
B_locatable_materials <- B_select_materials %>%
  filter(materials_badge == "Yes") %>%
  tabyl(materials_badge, materials_locatable) %>%
  mutate("Percent" = Yes/(Yes + `Requires permission` + No)*100) %>%
  select(Number = Yes, Percent) %>%
  mutate(Real_Stage = "Actually Locatable")

# correct materials
B_correct_materials <- B_select_materials %>%
  filter(materials_badge == "Yes") %>%
  tabyl(materials_badge, materials_correspond) %>%
  mutate("Percent" = Yes/(Yes + Unclear)*100) %>%
  select(Number = Yes, Percent) %>%
  mutate(Real_Stage = "Correct Materials")

# complete materials
B_complete_materials <- B_select_materials %>%
  filter(materials_badge == "Yes") %>%
  tabyl(materials_badge, materials_complete) %>%
  mutate("Percent" = `Yes, all of the materials appear to be available`/(`Yes, all of the materials appear to be available` + `Yes, but only some of the materials are available` + `No, not all of the materials are available` + `Unclear whether or not all the materials are available`)*100) %>%
  select(Number = `Yes, all of the materials appear to be available`, Percent) %>%
  mutate(Real_Stage = "Complete Materials")

# scripts available 
B_material_scripts_available <- B_select_materials %>%
  filter(materials_badge == "Yes") %>%
  tabyl(materials_badge, materials_explanation) %>%
  mutate("Percent" = Yes/(Yes + No)*100) %>%
  select(Number = Yes, Percent) %>%
  mutate(Real_Stage = "Scripts Available/\nExplanation Provided")

#### Bind all statistics

B_material_stats <- rbind(B_reportedly_available_materials, B_locatable_materials, B_correct_materials, B_complete_materials, B_material_scripts_available)

B_material_stats <- B_material_stats %>%
  mutate("Time" = "2019-20") 

#### Combine 1A and 1B stats together

all_material_stats <- rbind(A_material_stats, B_material_stats)
```

#### Plot combined data 
```{r combo-m-plot, echo=FALSE}
combined_materials_plot <- ggplot(all_material_stats, aes(y=Percent,  group = Time, colour = Time)) +
  coord_cartesian(ylim=c(0,100)) +
  geom_line(aes(colour=Time, x=Real_Stage), size = 1) +
  geom_point(aes(x=Real_Stage), size=3, position = position_dodge(width=0)) +
    scale_color_manual(values=c("#EC407A","#42A5F5"),
                     labels=c("2014-15 (n = 38)",
                              "2019-20 (n = 107)")) +
  theme(axis.text.y = element_text(size=9),
        axis.title.y = element_text(size=9)) +
  theme(axis.text.x = element_text(size=7),
        axis.title.x = element_text(size=9, margin = margin(t = 2, r = 0, b = 0, l = 0))) +
  easy_labs(y = "Percentage of Articles That Received an Open Materials Badge", x = "Material Sharing Criteria") +
  scale_x_discrete(limits=c("Reportedly Available","Actually Locatable","Correct Materials","Complete Materials", "Scripts Available/\nExplanation Provided")) +
    theme(legend.position=c(.2, .3)) +
  theme(legend.title=element_blank()) +
  theme(legend.text = element_text(size = 9)) +
  theme(legend.key.size = unit(1, "cm")) +
  theme(axis.line= element_line(), 
        panel.background = element_blank(), 
        panel.grid.minor = element_blank()) 

combined_materials_plot

```








# Discussion


\newpage

# References

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup
