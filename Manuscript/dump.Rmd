---
title: "dump"
author: "Jen Richmond"
date: "26/10/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1A time ttests

## data

Articles published in the latter part of 2014  had significantly higher open data scores (*M* = `r data_timeperiod_descriptives_A$mean_data_score[2]`, *SD* = `r data_timeperiod_descriptives_A$SD[2]`) than articles published in the first half of the year (*M* = `r data_timeperiod_descriptives_A$mean_data_score[1]`, *SD* = `r data_timeperiod_descriptives_A$SD[1]`), `r ttest_apa4_A$statistic`), however, there was no further increase across the early part of 2015 (*M* = `r data_timeperiod_descriptives_A$mean_data_score[3]`, *SD* = `r data_timeperiod_descriptives_A$SD[3]`), `r ttest_apa5_A$statistic`.

## materials
Open materials scores increased incrementally across 2014 and 2015; papers published in the first half of 2015 had significantly higher open materials scores (*M* = `r materials_timeperiod_descriptives_A$mean_materials_score[3]`, *SD* = `r materials_timeperiod_descriptives_A$SD[3]`) than those published in the first half of 2014,(*M* = `r materials_timeperiod_descriptives_A$mean_materials_score[1]`, *SD* = `r materials_timeperiod_descriptives_A$SD[1]`), `r ttest_apa9_A$statistic`. 

# 1B time ttests

In terms of changes over time, open data scores increased significantly from late 2019 (*M* = `r data_timeperiod_descriptives_B$mean_data_score[1]`, *SD* = `r data_timeperiod_descriptives_B$SD[1]`) into 2020 (*M* = `r data_timeperiod_descriptives_B$mean_data_score[2]`, *SD* = `r data_timeperiod_descriptives_B$SD[2]`), `r ttest_apa7_B$statistic`, but were stable across 2020, (*M* = `r data_timeperiod_descriptives_B$mean_data_score[3]`, *SD* = `r data_timeperiod_descriptives_B$SD[3]`)`r ttest_apa8_B$statistic`.

# cal proportions

```{r}
final1A <- final1A %>%
  mutate(data_level = case_when(open_data_score >= 15 ~ 'very high',
          open_data_score >= 10 ~ 'high',
          open_data_score >= 5 ~ 'low',
          open_data_score >= 0 ~ 'very low',
          TRUE ~ 'fail'
          )) %>%
  mutate(mat_level = case_when(open_materials_score >= 15 ~ 'very high',
          open_materials_score >= 10 ~ 'high',
          open_materials_score >= 5 ~ 'low',
          open_materials_score >= 0 ~ 'very low',
          TRUE ~ 'fail'
          ))

final1B <- final1B %>%
  mutate(data_level = case_when(open_data_score >= 15 ~ 'very high',
          open_data_score >= 10 ~ 'high',
          open_data_score >= 5 ~ 'low',
          open_data_score >= 0 ~ 'very low',
          TRUE ~ 'fail'
          )) %>%
  mutate(mat_level = case_when(open_materials_score >= 15 ~ 'very high',
          open_materials_score >= 10 ~ 'high',
          open_materials_score >= 5 ~ 'low',
          open_materials_score >= 0 ~ 'very low',
          TRUE ~ 'fail'
          ))

final1A %>%
    tabyl(data_level) # 78 % papers had open data scores < 5

final1B %>%
    tabyl(data_level) # 62 % papers had open material scores >15

final1A %>%
    tabyl(mat_level) # 71 % papers had open material scores < 5

final1B %>%
    tabyl(mat_level) # 71 % papers had open material scores > 15
                                
```


KEEP OR THROW OUT?? There are several ways in which using open science practices places researchers at a professional advantage. For example, using open science early in the research process can save researchers time later (Markowetz, 2015). Open science practices that document the evolution of a study’s data, from its raw form to its analysed form, allow researchers to detect and rectify errors more easily and efficiently than if the data hadn’t been recorded so transparently, perhaps over different servers, laptops and hard drives (van der Zee & Reich, 2018). In addition, researchers’ use of open science practices can increase their visibility and prominence in the field. Several studies have shown that when researchers share their data, they are significantly more likely to be cited than those who haven’t (e.g., Dorch et al., 2015). A greater number of citations not only increases the likelihood of others viewing a researcher’s work (McKiernan et al., 2016), but it can also signal that the research is of a higher calibre (Durieux & Gevenois, 2010), which highlights the reputational advantage open science may pose to researchers. In sum, there are several researcher-centric benefits to practicing open science, that may further motivate researchers to adopt open science practices, if *Psychological Science*, and others, were to promote them. KEEP OR THROW OUT? 